{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proper\n"
     ]
    }
   ],
   "source": [
    "from utils.layer_utils import *\n",
    "from utils.model_utils import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from tensorflow.keras.models import model_from_json \n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.57 s, sys: 395 ms, total: 1.96 s\n",
      "Wall time: 291 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(train_data, train_label), (val_data, val_label) =  keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# index_list = list(set(train_label))\n",
    "# train_data = np.array(train_data)\n",
    "# train_label = np.array([np.array([index_list.index(i)],dtype=np.uint8) for i in train_label])\n",
    "# val_data = np.array(val_data)\n",
    "# val_label = np.array([np.array([index_list.index(i)],dtype=np.uint8) for i in val_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\n",
      "Training labels shape:  (50000, 1)\n",
      "Validation data shape:  (10000, 32, 32, 3)\n",
      "Validation labels shape:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape: ', train_data.shape)\n",
    "print('Training labels shape: ', train_label.shape)\n",
    "print('Validation data shape: ', val_data.shape)\n",
    "print('Validation labels shape: ', val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = keras.utils.to_categorical(train_label)\n",
    "val_label = keras.utils.to_categorical(val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generator(X, y, batch_size, shuffle):\n",
    "#     base_gen = ImageDataGenerator()\n",
    "#     for X_base, y_base in base_gen.flow(X, y, batch_size=batch_size, shuffle=shuffle):\n",
    "#         X_batch = X_base / 255.0\n",
    "#         yield X_batch, y_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, y, batch_size, shuffle, scale=7):\n",
    "    base_gen = keras.preprocessing.image.ImageDataGenerator()\n",
    "    for X_base, y_base in base_gen.flow(X, y, batch_size=batch_size, shuffle=shuffle):\n",
    "        X_batch = np.zeros((X_base.shape[0], X_base.shape[1]*scale,\n",
    "                            X_base.shape[2]*scale, X_base.shape[3]), np.float32)\n",
    "        for i in range(X_base.shape[0]):\n",
    "            with Image.fromarray(X_base[i].astype(np.uint8)) as img:\n",
    "                img = img.resize((X_base.shape[1]*scale, X_base.shape[2]*scale), Image.LANCZOS)\n",
    "                X_batch[i] = np.asarray(img, np.float32) / 255.0\n",
    "        yield X_batch, y_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 2 µs, total: 14 µs\n",
      "Wall time: 16 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_classes = 10\n",
    "bs = 64 #batch size\n",
    "epc = 1 #number of epoches\n",
    "train_generator = generator(train_data, train_label, bs,True)\n",
    "val_generator = generator(val_data, val_label, bs,True)\n",
    "# train_datagen=ImageDataGenerator()\n",
    "# train_generator = train_datagen.flow(train_data_1, train_label_1, batch_size=bs)\n",
    "step_size_train = train_data.shape[0]//bs\n",
    "validation_steps=val_data.shape[0]//1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m6=PeleeNet(input_shape=(224,224,3), n_classes=n_classes)\n",
    "m6.compile(optimizer= 'Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "m6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_6 = m6.fit_generator(generator = train_generator,\n",
    "                   steps_per_epoch = step_size_train,\n",
    "                   epochs = epc,\n",
    "                   validation_data=val_generator,validation_steps = validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "acc = history_6.history['acc']\n",
    "val_acc = history_6.history['val_acc']\n",
    "\n",
    "loss = history_6.history['loss']\n",
    "val_loss = history_6.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m5=model5(input_shape=(224,224,3), n_classes=n_classes)\n",
    "m5.compile(optimizer= 'Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "m5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_5 = m5.fit_generator(generator = train_generator,\n",
    "                   steps_per_epoch = step_size_train,\n",
    "                   epochs = epc,\n",
    "                   validation_data=val_generator,validation_steps = validation_steps)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "acc = history_5.history['acc']\n",
    "val_acc = history_5.history['val_acc']\n",
    "\n",
    "loss = history_5.history['loss']\n",
    "val_loss = history_5.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# serialize weights to HDF5\n",
    "m5.save_weights(\"./models/imagenet/m5.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m4=model4(input_shape=(224,224,3), n_classes=n_classes)\n",
    "m4.compile(optimizer= 'Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "m4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_4 = m4.fit_generator(generator = train_generator,\n",
    "                   steps_per_epoch = step_size_train,\n",
    "                   epochs = epc,\n",
    "                   validation_data=val_generator,validation_steps = validation_steps)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "acc = history_4.history['acc']\n",
    "val_acc = history_4.history['val_acc']\n",
    "\n",
    "loss = history_4.history['loss']\n",
    "val_loss = history_4.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# serialize weights to HDF5\n",
    "m4.save_weights(\"./models/imagenet/m4.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m3=model3(input_shape=(224,224,3), n_classes=n_classes)\n",
    "m3.compile(optimizer= 'Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "m3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_3 = m3.fit_generator(generator = train_generator,\n",
    "                   steps_per_epoch = step_size_train,\n",
    "                   epochs = epc,\n",
    "                   validation_data=val_generator,validation_steps = validation_steps)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "acc = history_3.history['acc']\n",
    "val_acc = history_3.history['val_acc']\n",
    "\n",
    "loss = history_3.history['loss']\n",
    "val_loss = history_3.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# serialize weights to HDF5\n",
    "m3.save_weights(\"./models/imagenet/m3.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ecbm4040/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 16)      9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 224, 224, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 224, 224, 64)      1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 224, 224, 16)      9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 224, 224, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 224, 224, 64)      1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 224, 224, 16)      9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 224, 224, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 224, 224, 128)     2176      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 224, 224, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 224, 224, 128)     0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 112, 112, 64)      8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 112, 112, 16)      9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 112, 112, 64)      1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 112, 112, 16)      9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 112, 112, 64)      1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 112, 112, 16)      9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 112, 112, 64)      1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 112, 112, 16)      9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 112, 112, 256)     4352      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 112, 112, 256)     1024      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 112, 112, 256)     0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 56, 56, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 56, 56, 512)       8704      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 56, 56, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 56, 56, 512)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 28, 28, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 28, 28, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 28, 28, 64)        1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 28, 28, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 28, 28, 64)        1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 28, 28, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 28, 28, 704)       11968     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 28, 28, 704)       2816      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 28, 28, 704)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 704)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7050      \n",
      "=================================================================\n",
      "Total params: 285,610\n",
      "Trainable params: 279,530\n",
      "Non-trainable params: 6,080\n",
      "_________________________________________________________________\n",
      "CPU times: user 3.81 s, sys: 50.4 ms, total: 3.86 s\n",
      "Wall time: 3.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m2=model2(input_shape=(224,224,3), n_classes=n_classes)\n",
    "m2.compile(optimizer= 'Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "m2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ecbm4040/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,224,224,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_198-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node ConstantFoldingCtrl/loss/dense_loss/broadcast_weights/assert_broadcastable/AssertGuard/Switch_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,224,224,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_198-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node ConstantFoldingCtrl/loss/dense_loss/broadcast_weights/assert_broadcastable/AssertGuard/Switch_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_2 = m2.fit_generator(generator = train_generator,\n",
    "                   steps_per_epoch = step_size_train,\n",
    "                   epochs = epc,\n",
    "                   validation_data=val_generator,validation_steps = validation_steps)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "acc = history_2.history['acc']\n",
    "val_acc = history_2.history['val_acc']\n",
    "\n",
    "loss = history_2.history['loss']\n",
    "val_loss = history_2.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# serialize weights to HDF5\n",
    "m2.save_weights(\"./models/imagenet/m2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 224, 224, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 224, 224, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 224, 224, 64)      1088      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 224, 224, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 224, 224, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 224, 224, 64)      1088      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 224, 224, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 224, 224, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 224, 224, 128)     2176      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 112, 112, 64)      8256      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 112, 112, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 112, 112, 64)      1088      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 112, 112, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 112, 112, 64)      1088      \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 112, 112, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 112, 112, 64)      1088      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 112, 112, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 112, 112, 256)     4352      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 56, 56, 64)        16448     \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 56, 56, 512)       8704      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 28, 28, 64)        32832     \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 28, 28, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 28, 28, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 28, 28, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 28, 28, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 28, 28, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 28, 28, 704)       11968     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 704)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7050      \n",
      "=================================================================\n",
      "Total params: 282,806\n",
      "Trainable params: 278,128\n",
      "Non-trainable params: 4,678\n",
      "_________________________________________________________________\n",
      "CPU times: user 3.87 s, sys: 80.2 ms, total: 3.95 s\n",
      "Wall time: 3.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m1=model1(input_shape=(224,224,3), n_classes=n_classes)\n",
    "m1.compile(optimizer= 'Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,16,56,56] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_71/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node ConstantFoldingCtrl/loss_1/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Switch_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,16,56,56] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_71/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node ConstantFoldingCtrl/loss_1/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Switch_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_1 = m1.fit_generator(generator = train_generator,\n",
    "                   steps_per_epoch = step_size_train,\n",
    "                   epochs = epc,\n",
    "                   validation_data=val_generator,validation_steps = validation_steps)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "acc = history_1.history['acc']\n",
    "val_acc = history_1.history['val_acc']\n",
    "\n",
    "loss = history_1.history['loss']\n",
    "val_loss = history_1.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# serialize weights to HDF5\n",
    "m1.save_weights(\"./models/imagenet/m1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 224, 224, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 224, 224, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 224, 224, 64)      1088      \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 224, 224, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 224, 224, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 224, 224, 64)      1088      \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 224, 224, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 224, 224, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 224, 224, 64)      1088      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Average (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 112, 112, 64)      4160      \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 112, 112, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 112, 112, 64)      1088      \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 112, 112, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 112, 112, 64)      1088      \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 112, 112, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 112, 112, 64)      1088      \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 112, 112, 16)      9232      \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 112, 112, 128)     2176      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_7 (Average (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 56, 56, 64)        8256      \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 56, 56, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 56, 56, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 56, 56, 256)       4352      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 28, 28, 64)        16448     \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 28, 28, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 28, 28, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_116 (Conv2D)          (None, 28, 28, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_117 (Conv2D)          (None, 28, 28, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 28, 28, 16)        9232      \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 28, 28, 352)       5984      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 352)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                3530      \n",
      "=================================================================\n",
      "Total params: 235,222\n",
      "Trainable params: 231,440\n",
      "Non-trainable params: 3,782\n",
      "_________________________________________________________________\n",
      "CPU times: user 4.05 s, sys: 80.1 ms, total: 4.13 s\n",
      "Wall time: 4.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m0=DenseNet41(input_shape=(224,224,3), n_classes=10)\n",
    "m0.compile(optimizer= 'Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "m0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333/781 [===========>..................] - ETA: 4:59 - loss: 2.4320 - acc: 0.2789"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_0 = m0.fit_generator(generator = train_generator,\n",
    "                   steps_per_epoch = step_size_train,\n",
    "                   epochs = epc,\n",
    "                   validation_data=val_generator,validation_steps = validation_steps)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "acc = history_0.history['acc']\n",
    "val_acc = history_0.history['val_acc']\n",
    "\n",
    "loss = history_0.history['loss']\n",
    "val_loss = history_0.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# serialize weights to HDF5\n",
    "m0.save_weights(\"./models/imagenet/m0.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
